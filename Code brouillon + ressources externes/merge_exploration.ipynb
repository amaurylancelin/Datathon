{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = str(Path(os.getcwd()).absolute().parent)\n",
    "os.chdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/maximebonnin/Documents/Projects/SCOR/Datathon'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to merge data after concatenate data by year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for year in [2017,2018,2019]:\n",
    "    pathData = Path(f\"RawData/{year}/\")\n",
    "    paths = [pathData / name for name in os.listdir(pathData)]\n",
    "    dfs = [pd.read_excel(path) for path in paths]\n",
    "    df_summary = pd.concat(dfs, ignore_index=True)\n",
    "    df_summary[\"Year\"] = year\n",
    "    df_summary.to_csv(pathData / f\"{year}_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_test = pd.read_csv(pathData / f\"{year}_summary.csv\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_key_str(df):\n",
    "\n",
    "    df[\"GP\"] = df[\"GP\"].fillna(\"\")\n",
    "    df[\"Block\"] = df[\"Block\"].fillna(\"\").astype(str)\n",
    "    \n",
    "\n",
    "    df[\"key_str\"] = df[\"State\"].astype(str) + \"_\" + df[\"District\"].astype(str)\n",
    "    df[\"key_str\"] += \"_\" + df[\"Sub-District\"].astype(str) + \"_\"\n",
    "    df[\"key_str\"] += df[\"Block\"].astype(str) + \"_\"\n",
    "    df[\"key_str\"] += df[\"GP\"].astype(str)\n",
    "\n",
    "    df[\"key_str\"] = df[\"key_str\"].str.lower()\n",
    "\n",
    "columns_to_keep = ['Season',\n",
    "       'Crop', 'Area Sown (Ha)', 'Area Insured (Ha)', 'SI Per Ha (Inr/Ha)',\n",
    "       'Sum Insured (Inr)', 'Indemnity Level', 'key_str', 'Loss']\n",
    "\n",
    "yields = ['State', 'Cluster', 'District', 'Sub-District', 'Block', 'GP', 'Season',\n",
    "        '2000 Yield', '2001 Yield', '2002 Yield', '2003 Yield', '2004 Yield', \n",
    "        '2005 Yield', '2006 Yield', '2007 Yield', '2008 Yield', '2009 Yield', \n",
    "        '2010 Yield', '2011 Yield', '2012 Yield', '2013 Yield', '2014 Yield', \n",
    "        '2015 Yield', '2016 Yield', '2017 Yield', '2018 Yield', 'key_str'\n",
    "]\n",
    "\n",
    "def merge_year(dfs):\n",
    "    df_merged = dfs[0].copy()[columns_to_keep]\n",
    "    df_merged = df_merged.merge(dfs[1][columns_to_keep], on=[\"Season\", \"key_str\"],suffixes=('_2017', '_2018'))\n",
    "    df_merged = df_merged.merge(dfs[2][columns_to_keep], on=[\"Season\", \"key_str\"],suffixes=(\"_2018\", '_2019'))\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "def compute_mean_by_crop(df): \n",
    "    stats = {}\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"Crop\"] = df[\"Crop\"].str.lower()\n",
    "    \n",
    "    for i in trange(df.shape[0]):\n",
    "        crop = df.iloc[i][\"Crop\"]\n",
    "        if crop not in stats:\n",
    "            stats[crop] = {}\n",
    "            stats[crop][\"N\"] = 0 \n",
    "            stats[crop][\"area_sown\"] = 0 \n",
    "            stats[crop][\"area_insured\"] = 0\n",
    "            stats[crop][\"si_per_ha\"] = 0\n",
    "            stats[crop][\"sum_insured\"] = 0\n",
    "            stats[crop][\"indemnity_level\"] = 0\n",
    "\n",
    "            for year in range(2000,2020):\n",
    "                try:\n",
    "                    stats[crop][f\"yield_{year}\"] = 0\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "\n",
    "        area_sown = df.iloc[i][\"Area Sown (Ha)\"]\n",
    "        area_insured = df.iloc[i][\"Area Insured (Ha)\"]\n",
    "        si_per_ha = df.iloc[i][\"SI Per Ha (Inr/Ha)\"]\n",
    "        sum_insured = df.iloc[i][\"Sum Insured (Inr)\"]\n",
    "        indemnity_level = df.iloc[i][\"Indemnity Level\"]\n",
    "        \n",
    "        stats[crop][\"area_sown\"] += area_sown\n",
    "        stats[crop][\"area_insured\"] += area_insured\n",
    "        stats[crop][\"si_per_ha\"] += si_per_ha\n",
    "        stats[crop][\"sum_insured\"] += sum_insured\n",
    "        stats[crop][\"indemnity_level\"] += indemnity_level\n",
    "        stats[crop][\"N\"] += 1\n",
    "\n",
    "        for year in range(2000,2020):\n",
    "            try:\n",
    "                stats[crop][f\"yield_{year}\"] += df.iloc[i][f\"{year} Yield\"]\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "    for crop in stats.keys():\n",
    "        for index in stats[crop].keys():\n",
    "            if index != \"N\":\n",
    "                stats[crop][index] /= stats[crop][\"N\"]\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def clean(df, stats):\n",
    "    # change it to tack into account \n",
    "    # pd.isna instead of this method\n",
    "    df[\"Crop\"] = df[\"Crop\"].str.lower()\n",
    "\n",
    "    for crop in stats.keys():\n",
    "        \n",
    "        df[df[\"Crop\"] == crop][\"Area Sown (Ha)\"].astype(float).fillna(stats[crop][\"area_sown\"], inplace=True)\n",
    "        df[df[\"Crop\"] == crop][\"Area Insured (Ha)\"].astype(float).fillna(stats[crop][\"area_insured\"], inplace=True)\n",
    "        df[df[\"Crop\"] == crop][\"SI Per Ha (Inr/Ha)\"].astype(float).fillna(stats[crop][\"si_per_ha\"], inplace=True)\n",
    "        df[df[\"Crop\"] == crop][\"Sum Insured (Inr)\"].astype(float).fillna(stats[crop][\"sum_insured\"], inplace=True)\n",
    "        df[df[\"Crop\"] == crop][\"Indemnity Level\"].astype(float).fillna(stats[crop][\"indemnity_level\"], inplace=True)\n",
    "    \n",
    "    \n",
    "\n",
    "        for year in range(2000,2019):\n",
    "            try:\n",
    "                df[df[\"Crop\"] == crop][f\"{year} Yield\"].fillna(stats[crop][f\"yield_{year}\"], inplace=True)\n",
    "                df[df[\"Crop\"] == crop][f\"{year} Yield\"].fillna(-1, inplace=True)\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "    df[\"Area Sown (Ha)\"].fillna(-1, inplace=True)\n",
    "    df[\"Area Insured (Ha)\"].fillna(-1, inplace=True)\n",
    "    df[\"SI Per Ha (Inr/Ha)\"].fillna(-1, inplace=True)\n",
    "    df[\"Sum Insured (Inr)\"].fillna(-1, inplace=True)\n",
    "    df[\"Indemnity Level\"].fillna(-1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_area_sown(df):\n",
    "    newValues = []\n",
    "    for value in df[\"Area Sown (Ha)\"]:\n",
    "        try:\n",
    "            value = float(value)\n",
    "            newValues.append(value)\n",
    "        except ValueError:\n",
    "            newValues.append(np.NaN)\n",
    "    df[\"Area Sown (Ha)\"] = newValues\n",
    "    return df\n",
    "    \n",
    "\n",
    "def clean_yield(df):\n",
    "    \n",
    "    for year in range(2000,2020):\n",
    "        \n",
    "        try:\n",
    "            df[f\"{year} Yield\"]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "        newValues = []\n",
    "        for value in df[f\"{year} Yield\"]:\n",
    "            try:\n",
    "                value = float(value)\n",
    "                newValues.append(value)\n",
    "            except ValueError:\n",
    "                newValues.append(np.NaN)\n",
    "        df[f\"{year} Yield\"] = newValues\n",
    "        # print(\"Compute Mean...\")\n",
    "        # print(\"Adding mean...\")\n",
    "        \n",
    "        \n",
    "    return df\n",
    "    \n",
    "def normalization_other(df):\n",
    "    df[\"Area Sown (Ha)\"] = (df[\"Area Sown (Ha)\"] - df[\"Area Sown (Ha)\"].mean())/df[\"Area Sown (Ha)\"].std()\n",
    "    df[\"Area Insured (Ha)\"] = (df[\"Area Insured (Ha)\"] - df[\"Area Insured (Ha)\"].mean())/df[\"Area Insured (Ha)\"].std()\n",
    "    df[\"SI Per Ha (Inr/Ha)\"] = (df[\"SI Per Ha (Inr/Ha)\"] - df[\"SI Per Ha (Inr/Ha)\"].mean())/df[\"SI Per Ha (Inr/Ha)\"].std()\n",
    "    df[\"Sum Insured (Inr)\"] = (df[\"Sum Insured (Inr)\"] - df[\"Sum Insured (Inr)\"].mean())/df[\"Sum Insured (Inr)\"].std()\n",
    "    df[\"Indemnity Level\"] = (df[\"Indemnity Level\"] - df[\"Indemnity Level\"].mean())/df[\"Indemnity Level\"].std()\n",
    "\n",
    "    return df\n",
    "\n",
    "def normalization_yield(df):\n",
    "    for year in range(2000,2019):\n",
    "        try:\n",
    "            df[f\"{year} Yield\"] = (df[f\"{year} Yield\"] - df[f\"{year} Yield\"].mean())/df[f\"{year} Yield\"].std()\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_Loss(df,year):\n",
    "    \"\"\"return a new_df with a new collumn Loss\"\"\"\n",
    "    Y=np.array([df[f'{y} Yield'] for y in np.arange(year-6,year+1)])\n",
    "    theta=np.array(df[\"Indemnity Level\"])\n",
    "    Y=np.partition(Y,2,axis=0)\n",
    "    Y=Y[2:,:]\n",
    "    print(Y.shape)\n",
    "    threshold=np.mean(Y, axis=0)*theta\n",
    "    S=np.array(df[\"Sum Insured (Inr)\"])\n",
    "    L=np.sum(S*np.maximum(0,threshold-Y),axis=0)/threshold\n",
    "    new_df=df\n",
    "    new_df[\"Loss\"]=L\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Data/RawData/2018/2018_Chhattisgarh_Rabi.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec58480a89ab4398a776fd4e77725094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/622 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = compute_mean_by_crop(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_area_sown(df)\n",
    "df = clean_yield(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/pandas/core/generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>District</th>\n",
       "      <th>Sub-District</th>\n",
       "      <th>Block</th>\n",
       "      <th>GP</th>\n",
       "      <th>Season</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Area Sown (Ha)</th>\n",
       "      <th>Area Insured (Ha)</th>\n",
       "      <th>...</th>\n",
       "      <th>2007 Yield</th>\n",
       "      <th>2008 Yield</th>\n",
       "      <th>2009 Yield</th>\n",
       "      <th>2010 Yield</th>\n",
       "      <th>2011 Yield</th>\n",
       "      <th>2012 Yield</th>\n",
       "      <th>2013 Yield</th>\n",
       "      <th>2014 Yield</th>\n",
       "      <th>2015 Yield</th>\n",
       "      <th>2016 Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>1</td>\n",
       "      <td>Balod</td>\n",
       "      <td>Balod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>castor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>625.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>342.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>1</td>\n",
       "      <td>Balod</td>\n",
       "      <td>Dondi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>castor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>625.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>1</td>\n",
       "      <td>Balod</td>\n",
       "      <td>Dondilohara</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>castor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>625.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>318.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>1</td>\n",
       "      <td>Balod</td>\n",
       "      <td>Dondilohara</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>castor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>625.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>318.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>1</td>\n",
       "      <td>Balod</td>\n",
       "      <td>Gurur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>castor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>625.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>3</td>\n",
       "      <td>Surguja</td>\n",
       "      <td>Lakhanpur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>castor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>377.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>244.8</td>\n",
       "      <td>272.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>3</td>\n",
       "      <td>Surguja</td>\n",
       "      <td>Udaipur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>castor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>377.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>244.8</td>\n",
       "      <td>272.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>3</td>\n",
       "      <td>Surguja</td>\n",
       "      <td>Lundra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>castor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>377.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>288.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>3</td>\n",
       "      <td>Surguja</td>\n",
       "      <td>Lundra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>castor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>377.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>288.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>3</td>\n",
       "      <td>Surguja</td>\n",
       "      <td>Batauli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>castor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>377.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>244.8</td>\n",
       "      <td>272.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Cluster District Sub-District  Block  GP Season    Crop  \\\n",
       "0    Chhattisgarh        1    Balod        Balod    NaN NaN   Rabi  castor   \n",
       "1    Chhattisgarh        1    Balod        Dondi    NaN NaN   Rabi  castor   \n",
       "2    Chhattisgarh        1    Balod  Dondilohara    NaN NaN   Rabi  castor   \n",
       "3    Chhattisgarh        1    Balod  Dondilohara    NaN NaN   Rabi  castor   \n",
       "4    Chhattisgarh        1    Balod        Gurur    NaN NaN   Rabi  castor   \n",
       "..            ...      ...      ...          ...    ...  ..    ...     ...   \n",
       "617  Chhattisgarh        3  Surguja    Lakhanpur    NaN NaN   Rabi  castor   \n",
       "618  Chhattisgarh        3  Surguja      Udaipur    NaN NaN   Rabi  castor   \n",
       "619  Chhattisgarh        3  Surguja       Lundra    NaN NaN   Rabi  castor   \n",
       "620  Chhattisgarh        3  Surguja       Lundra    NaN NaN   Rabi  castor   \n",
       "621  Chhattisgarh        3  Surguja      Batauli    NaN NaN   Rabi  castor   \n",
       "\n",
       "     Area Sown (Ha)  Area Insured (Ha)  ...  2007 Yield  2008 Yield  \\\n",
       "0              -1.0         625.142857  ...         NaN         NaN   \n",
       "1              -1.0         625.142857  ...         NaN         NaN   \n",
       "2              -1.0         625.142857  ...         NaN         NaN   \n",
       "3              -1.0         625.142857  ...         NaN         NaN   \n",
       "4              -1.0         625.142857  ...         NaN         NaN   \n",
       "..              ...                ...  ...         ...         ...   \n",
       "617            -1.0         377.500000  ...       244.8       272.0   \n",
       "618            -1.0         377.500000  ...       244.8       272.0   \n",
       "619            -1.0         377.500000  ...       288.0       410.0   \n",
       "620            -1.0         377.500000  ...       288.0       410.0   \n",
       "621            -1.0         377.500000  ...       244.8       272.0   \n",
       "\n",
       "     2009 Yield  2010 Yield  2011 Yield  2012 Yield  2013 Yield  2014 Yield  \\\n",
       "0           NaN       342.0       276.0       220.0       130.0       349.0   \n",
       "1           NaN       210.0       180.0       190.0       267.0       160.0   \n",
       "2           NaN       318.0       310.0       250.0       244.0       340.0   \n",
       "3           NaN       318.0       310.0       401.0       209.0       321.0   \n",
       "4           NaN       103.0       274.0       114.0       191.0       169.0   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "617       259.0       183.0       417.0      1105.0       581.0       790.0   \n",
       "618       259.0       326.0       400.0       460.0       614.0       555.0   \n",
       "619       259.0       668.0       897.0       450.0       375.0       477.0   \n",
       "620       259.0       668.0       897.0       450.0       545.0       428.0   \n",
       "621       259.0       668.0       897.0       593.0       647.0       547.0   \n",
       "\n",
       "     2015 Yield  2016 Yield  \n",
       "0           NaN         NaN  \n",
       "1           NaN         NaN  \n",
       "2           NaN         NaN  \n",
       "3           NaN         NaN  \n",
       "4           NaN         NaN  \n",
       "..          ...         ...  \n",
       "617         NaN         NaN  \n",
       "618         NaN         NaN  \n",
       "619         NaN         NaN  \n",
       "620         NaN         NaN  \n",
       "621         NaN         NaN  \n",
       "\n",
       "[622 rows x 28 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.copy()\n",
    "df_new = clean(df_new, stats)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[\"Area Insured (Ha)\"].fillna(0).unique().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(columns=[\"Crop\"]).query(\"Crop == 'rice'\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for year in range(2017,2020):\n",
    "    pathData = Path(f\"RawData/{year}/\")\n",
    "    df = pd.read_csv(pathData / f\"{year}_summary.csv\")\n",
    "    dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2017 ...\n",
      "Adding key...\n",
      "Adding area sown...\n",
      "Adding yield...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11688f31f6284e0e8051f8b2ec2ba83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Loss...\n",
      "(5, 632543)\n",
      "Cleaning ...\n",
      "Normalizing...\n",
      "Year 2018 ...\n",
      "Adding key...\n",
      "Adding area sown...\n",
      "Adding yield...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23292f90c1c940eead6af3d1de64c197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Loss...\n",
      "(5, 633324)\n",
      "Cleaning ...\n",
      "Normalizing...\n",
      "Year 2019 ...\n",
      "Adding key...\n",
      "Adding area sown...\n",
      "Adding yield...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648a1b5519224522bb0b51e2977a7be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Loss...\n",
      "(5, 690412)\n",
      "Cleaning ...\n",
      "Normalizing...\n"
     ]
    }
   ],
   "source": [
    "new_dfs = []\n",
    "for i, df in enumerate(dfs):\n",
    "    print(f\"Year {2017+i} ...\")\n",
    "    print('Adding key...')\n",
    "    add_key_str(df)\n",
    "    # print(df.columns)\n",
    "    print(\"Adding area sown...\")\n",
    "    clean_area_sown(df)\n",
    "    print(\"Adding yield...\")\n",
    "    clean_yield(df)\n",
    "    print(\"Adding Loss...\")\n",
    "    df = add_Loss(df, 2015+i)\n",
    "    print(\"Cleaning ...\")\n",
    "    df = clean(df)\n",
    "    print(\"Normalizing...\")\n",
    "    df = normalization_other(df)\n",
    "    new_dfs.append(df)\n",
    "\n",
    "df_merged = merge_year(new_dfs)\n",
    "df_merged = pd.get_dummies(df_merged, columns=[\"Crop\", \"Crop_2017\", \"Crop_2018\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = new_dfs[-1].copy()\n",
    "del dfs, df, new_dfs\n",
    "df_summary_merged = df_merged.merge(df_2019[yields], on=[\"Season\", \"key_str\"])\n",
    "df_summary_merged = normalization_yield(df_summary_merged)\n",
    "df_summary_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_summary_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/01/nfq6qhcj2j7dqfld6ps6vhbc0000gn/T/ipykernel_11449/1385137936.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_summary_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_summary_merged' is not defined"
     ]
    }
   ],
   "source": [
    "df_summary_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge years for every state and season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathData = Path('Data/RawData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_infos(filename):\n",
    "    state, season = filename.split(\"_\")[1], filename.split(\"_\")[-1].replace(\".xlsx\",\"\")\n",
    "    return state, season\n",
    "\n",
    "def key_state_season(filename):\n",
    "    filename = str(filename)\n",
    "    return filename.split(\"_\")[1]+\"_\"+filename.split(\"_\")[-1].replace(\".xlsx\",\"\")\n",
    "\n",
    "\n",
    "def merge_DF(paths):\n",
    "\n",
    "    dfs = [pd.read_excel(path) for path in paths]\n",
    "    \n",
    "    new_dfs = []\n",
    "    for i, df in enumerate(dfs):\n",
    "        add_key_str(df)\n",
    "        # print(df.columns)\n",
    "        clean_area_sown(df)\n",
    "        clean_yield(df)\n",
    "        # df = add_Loss(df, 2015+i)\n",
    "        df = clean(df)\n",
    "        df = normalization_other(df)\n",
    "        new_dfs.append(df)\n",
    "\n",
    "    df_merged = merge_year(new_dfs)\n",
    "    return df_merged    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allStatesAndSeason = {key_state_season(x) for x in pathData.glob(\"*/*.xlsx\")}\n",
    "len(allStatesAndSeason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df[\"Area Sown (Ha)\"] = df[\"Area Sown (Ha)\"].astype(float).fillna(-1)\n",
    "    df[\"Area Insured (Ha)\"] = df[\"Area Insured (Ha)\"].astype(float).fillna(-1)\n",
    "    df[\"SI Per Ha (Inr/Ha)\"] = df[\"SI Per Ha (Inr/Ha)\"].astype(float).fillna(-1)\n",
    "    df[\"Sum Insured (Inr)\"] = df[\"Sum Insured (Inr)\"].astype(float).fillna(-1)\n",
    "    df[\"Indemnity Level\"] = df[\"Indemnity Level\"].astype(float).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/Users/maximebonnin/Documents/Projects/SCOR/Datathon/Data/RawData/2018/2018_Andhra Pradesh_Kharif.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb1f478eff746c38039bec5171626c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18735 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/01/nfq6qhcj2j7dqfld6ps6vhbc0000gn/T/ipykernel_910/1768967789.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_mean_by_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/01/nfq6qhcj2j7dqfld6ps6vhbc0000gn/T/ipykernel_910/3797729305.py\u001b[0m in \u001b[0;36mcompute_mean_by_crop\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcrop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"N\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "stats = compute_mean_by_crop(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arhar', 'Paddy', 'Bajra', 'Castor', 'Chilli IRR', 'Chilli',\n",
       "       'Cotton Un-IRR', 'Groundnut Un-IRR', 'Groundnut', 'Jowar', 'Maize',\n",
       "       'Moong', 'Navane', 'Sugarcane Plant', 'Sugarcane Ratoon',\n",
       "       'Sunflower', 'Urad', 'Chilli Un-IRR', 'Cotton IRR',\n",
       "       'Groundnut IRR'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_key_str(df)\n",
    "# print(df.columns)\n",
    "print(\"Adding area sown...\")\n",
    "clean_area_sown(df)\n",
    "print(\"Adding yield...\")\n",
    "clean_yield(df)\n",
    "print(\"Adding Loss...\")\n",
    "df = add_Loss(df, 2015+i)\n",
    "print(\"Cleaning ...\")\n",
    "df = clean(df)\n",
    "print(\"Normalizing...\")\n",
    "df = normalization_other(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70000, 80000, 71250, 75000, 62500, 72500, 67500, 65000, 40000])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"Crop == 'Paddy'\")[\"SI Per Ha (Inr/Ha)\"].fillna(-1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5659a3733c446ea0c27bb3053f5631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('Data/RawData/2017/2017_Rajasthan_Kharif.xlsx'), PosixPath('Data/RawData/2018/2018_Rajasthan_Kharif.xlsx'), PosixPath('Data/RawData/2019/2019_Rajasthan_Kharif.xlsx')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90b9970846a4057abceeca4eba13d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 28670)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083ecdcd1afa48a59a1298f6a2b1dc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 28659)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d40ff4429044659b24d12e24d544de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 31029)\n",
      "   Season Crop_2017  Area Sown (Ha)_2017  Area Insured (Ha)_2017  \\\n",
      "0  kharif     arhar             1.540322               -0.946948   \n",
      "1  kharif     arhar             1.540322               -0.946948   \n",
      "2  kharif     arhar             1.540322               -0.946948   \n",
      "3  kharif     arhar             1.540322               -0.946948   \n",
      "4  kharif     arhar             1.540322               -0.946948   \n",
      "\n",
      "   SI Per Ha (Inr/Ha)_2017  Sum Insured (Inr)_2017  Indemnity Level_2017  \\\n",
      "0                 1.843366               -0.874697             -0.999983   \n",
      "1                 1.843366               -0.874697             -0.999983   \n",
      "2                 1.843366               -0.874697             -0.999983   \n",
      "3                 1.843366               -0.874697             -0.999983   \n",
      "4                 1.843366               -0.874697             -0.999983   \n",
      "\n",
      "                 key_str  Loss_2017 Crop_2018  ...  Sum Insured (Inr)_2018  \\\n",
      "0  rajasthan_alwar_nan__        NaN     bajra  ...                0.026071   \n",
      "1  rajasthan_alwar_nan__        NaN     bajra  ...                0.026071   \n",
      "2  rajasthan_alwar_nan__        NaN     bajra  ...                0.026071   \n",
      "3  rajasthan_alwar_nan__        NaN     bajra  ...                0.026071   \n",
      "4  rajasthan_alwar_nan__        NaN     bajra  ...                0.026071   \n",
      "\n",
      "   Indemnity Level_2018  Loss_2018   Crop  Area Sown (Ha)  Area Insured (Ha)  \\\n",
      "0                  -1.0        0.0  arhar       -1.014646          -0.924292   \n",
      "1                  -1.0        0.0  arhar       -1.014646          -0.924292   \n",
      "2                  -1.0        0.0  arhar       -1.014646          -0.924292   \n",
      "3                  -1.0        0.0  arhar       -1.014646          -0.924292   \n",
      "4                  -1.0        0.0  arhar       -1.014646          -0.924292   \n",
      "\n",
      "  SI Per Ha (Inr/Ha)  Sum Insured (Inr)  Indemnity Level  Loss  \n",
      "0          -2.402869          -1.081577        -0.999984   NaN  \n",
      "1          -2.402869          -1.081577        -0.999984   NaN  \n",
      "2          -2.402869          -1.081577        -0.999984   NaN  \n",
      "3          -2.402869          -1.081577        -0.999984   NaN  \n",
      "4          -2.402869          -1.081577        -0.999984   NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "[PosixPath('Data/RawData/2017/2017_Haryana_Kharif.xlsx'), PosixPath('Data/RawData/2018/2018_Haryana_Kharif.xlsx'), PosixPath('Data/RawData/2019/2019_Haryana_Kharif.xlsx')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b761d54c079a46d5ac0e8ca89fe73bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 485)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a15b824b46b4deb806111c29d18a2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 485)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9455b7637148e187fd44993867dc35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 451)\n",
      "Empty DataFrame\n",
      "Columns: [Crop_2017, Area Sown (Ha)_2017, Area Insured (Ha)_2017, SI Per Ha (Inr/Ha)_2017, Sum Insured (Inr)_2017, Indemnity Level_2017, Loss_2017, Crop_2018, Area Sown (Ha)_2018, Area Insured (Ha)_2018, SI Per Ha (Inr/Ha)_2018, Sum Insured (Inr)_2018, Indemnity Level_2018, Loss_2018, Season, Crop, Area Sown (Ha), Area Insured (Ha), SI Per Ha (Inr/Ha), Sum Insured (Inr), Indemnity Level, key_str, Loss]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n",
      "[PosixPath('Data/RawData/2017/2017_Telangana_Kharif.xlsx'), PosixPath('Data/RawData/2018/2018_Telangana_Kharif.xlsx'), PosixPath('Data/RawData/2019/2019_Telangana_Kharif.xlsx')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b34f0110614c55ab5c06cae1ccc695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 13894)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ddb2fff9ad84617bfc6062772e7d0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 13894)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2244a0404eca41ea8d53eab5ff794680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 17928)\n",
      "Empty DataFrame\n",
      "Columns: [Crop_2017, Area Sown (Ha)_2017, Area Insured (Ha)_2017, SI Per Ha (Inr/Ha)_2017, Sum Insured (Inr)_2017, Indemnity Level_2017, Loss_2017, Crop_2018, Area Sown (Ha)_2018, Area Insured (Ha)_2018, SI Per Ha (Inr/Ha)_2018, Sum Insured (Inr)_2018, Indemnity Level_2018, Loss_2018, Season, Crop, Area Sown (Ha), Area Insured (Ha), SI Per Ha (Inr/Ha), Sum Insured (Inr), Indemnity Level, key_str, Loss]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n",
      "[PosixPath('Data/RawData/2017/2017_Madhya Pradesh_Rabi.xlsx'), PosixPath('Data/RawData/2018/2018_Madhya Pradesh_Rabi.xlsx'), PosixPath('Data/RawData/2019/2019_Madhya Pradesh_Rabi.xlsx')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d51597027a4866b553e372144af7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'2015 Yield'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '2015 Yield'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/01/nfq6qhcj2j7dqfld6ps6vhbc0000gn/T/ipykernel_13663/3590185103.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_DF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathData\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"Unified\"\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"{key}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/01/nfq6qhcj2j7dqfld6ps6vhbc0000gn/T/ipykernel_13663/1137635155.py\u001b[0m in \u001b[0;36mmerge_DF\u001b[0;34m(paths)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mclean_area_sown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mclean_yield\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2015\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalization_other\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/01/nfq6qhcj2j7dqfld6ps6vhbc0000gn/T/ipykernel_13663/642014655.py\u001b[0m in \u001b[0;36madd_Loss\u001b[0;34m(df, year)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;34m\"\"\"return a new_df with a new collumn Loss\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{y} Yield'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Indemnity Level\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/01/nfq6qhcj2j7dqfld6ps6vhbc0000gn/T/ipykernel_13663/642014655.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;34m\"\"\"return a new_df with a new collumn Loss\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{y} Yield'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Indemnity Level\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '2015 Yield'"
     ]
    }
   ],
   "source": [
    "notFull = []\n",
    "for key in tqdm(allStatesAndSeason):\n",
    "    paths = [x for x in pathData.glob(f\"*/*_{key}.xlsx\")]\n",
    "    paths.sort()\n",
    "    if len(paths)==3:\n",
    "        print(paths)\n",
    "        df = merge_DF(paths)\n",
    "        print(df.head())\n",
    "        df.to_csv(pathData / \"Unified\" / f\"{key}.csv\")\n",
    "    else:\n",
    "        notFull.append(key)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"2018\" < \"2097\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bihar_Rabi']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
